# 爬取多頁的職缺內容,將各個職缺內容存到csv檔
import requests
import bs4
import csv
import random, time

url_A = 'https://www.104.com.tw/jobs/search/?ro=0&jobcat=2007000000&keyword=%E8%B3%87%E8%A8%8A&expansionType=area%2Cspec%2Ccom%2Cjob%2Cwf%2Cwktm&order=15&asc=0&page=1&mode=s&jobsource=2018indexpoc'
url_B = '&mode=s&jobsource=2018indexpoc'
all_job_datas = []
for page in range(1, 5 + 1):
    url = url_A + str(page) + url_B
    print(url)
    htmlFile = requests.get(url)
    ObjSoup = bs4.BeautifulSoup(htmlFile.text, 'lxml')
    jobs = ObjSoup.find_all('article', class_='js-job-item')  # 搜尋所有職缺

    for job in jobs:
        job_name = job.find('a', class_="js-job-link").text  # 職缺名稱
        job_company = job.get('data-cust-name')  # 公司名稱
        job_industry = job.get('data-indcat-desc')  #產業類別
        job_loc = job.find('ul', class_='job-list-intro').find('li').text  # 地址/上班地點
        job_pay = job.find('span', class_='b-tag--default').text  # 工作待遇
        job_info = job.find('p').text  # 工作內容
        job_url = job.find('a').get('href')  # 網址
        job_data = {'職缺名稱': job_name, '公司名稱': job_company,'產業類別': job_industry, '上班地點': job_loc,
                    '工作待遇': job_pay, '工作內容': job_info,'網址': job_url}
        all_job_datas.append(job_data)
    time.sleep(random.randint(1, 3))

fn = '104joblist3.csv'  # 取CSV檔名
columns_name = ['職缺名稱', '公司名稱', '產業類別', '上班地點', '工作待遇', '工作內容', '網址' ]  # 第一欄的名稱
with open(fn, 'w', newline='') as csvFile:  # 定義CSV的寫入檔,並且每次寫入完會換下一行
    dictWriter = csv.DictWriter(csvFile, fieldnames=columns_name)  # 定義寫入器
    dictWriter.writeheader()
    for data in all_job_datas:
        dictWriter.writerow(data)
